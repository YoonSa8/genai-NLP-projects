probabilistic graphical models.
These offer several useful properties:
1. They provide a simple way to visualize the structure of a probabilistic model
and can be used to design and motivate new models.
2. Insights into the properties of the model, including conditional independence
properties, can be obtained by inspection of the graph.
3. Complex computations, required to perform inference and learning in sophisticated models, can be expressed in terms of graphical manipulations, in which underlying mathematical expressions are carried along implicitly.

A graph comprises nodes (also called vertices) connected by links (also known as edges or arcs). In a probabilistic graphical model, each node represents a random variable (or group of random variables), and the links express probabilistic relationships between these variables 

8.1. Bayesian Networks
Bayesian networks (also known as directed graphical models) are a fundamental tool in probabilistic modeling. They allow us to represent complex probability distributions efficiently by leveraging conditional independence and the factorization of the joint distribution. These models use directed acyclic graphs (DAGs) to describe dependencies among random variables.

it can also be used to Reducing computational complexity by breaking down the joint probability distribution into simpler conditional distributions.

Factorization of Joint Distributions in Bayesian Networks
To understand how Bayesian networks work, let’s begin with a simple example.
Consider a joint probability distribution over three variables: p(a,b,c)
Using the product rule of probability, we can decompose it as:p(a,b,c)=p(c∣a,b)p(a,b)
Applying the product rule again: p(a,b,c)=p(c∣a,b)p(b∣a)p(a)
This decomposition shows how the joint distribution can be represented as a sequence of conditional probabilities, making it easier to work with.
   a → b → c
a is the parent of b, and  b is the parent of 𝑐 
The missing direct connection between 𝑎 and 𝑐 suggests that 𝑐 is conditionally independent of 𝑎 given 𝑏.

General Case: Factorization in Large Networks For a general Bayesian network with 𝐾 variables 𝑥1,𝑥2,…,𝑥𝐾, the joint probability factorizes as:
𝑝(𝑥1,𝑥2,...,𝑥𝐾)=∏ 𝑝(𝑥𝑘∣𝑝𝑎𝑘)
              k=1
where 𝑝𝑎𝑘 represents the parent nodes of 𝑥𝑘. This equation captures the factorization property of Bayesian networks

Directed Acyclic Graphs (DAGs)
A Bayesian network must be a Directed Acyclic Graph (DAG), meaning: Directed: The edges have a direction (e.g., arrows point from cause to effect).
Acyclic: No cycles exist (i.e., you cannot start from a node and follow the arrows to return to the same node).

Why must it be acyclic?
Without cycles, the conditional probabilities can be ordered and properly computed.
Cyclic graphs would require infinitely recursive probability calculations.

8.1.1 Example: Polynomial regression
To illustrate Bayesian networks, Bishop provides an example based on Bayesian polynomial regression, introduced in Section 1.2.6. 
The key variables in this model include:
𝑤: The vector of polynomial coefficients.
𝑡=(𝑡1,𝑡2,...,𝑡𝑁): Observed target values
𝑥=(𝑥1,𝑥2,...,𝑥𝑁): Input data (not treated as random variables).
𝛼: A hyperparameter representing the precision of the Gaussian prior over w.
𝜎^2: Noise variance in observations.
to explain how the graph has been develop look at page 363
The required predictive distribution fort is then obtained, from the sum rule of probability, by integrating out the model parameters w so that
p(t|x, x, t, α, σ2) ∝∫ p(t, t,w|x, x, α, σ^2) dw
where we are implicitly setting the random variables in t to the specific values observed
in the data set. The details of this calculation were discussed in Chapter 3.

8.1.2 Generative models
A generative model explicitly defines how data is generated by sampling from probability distributions.
Ancestral Sampling Algorithm
To sample from a Bayesian network:
Start with a topological ordering of nodes (ensuring parents are sampled before children).
Sample from the prior distributions.
Progressively sample child nodes given their parent values.
This process is called ancestral sampling and is used to generate synthetic data from the model.
eg.    B → G ← F
B (battery state) and 𝐹 (fuel state) influence 𝐺 (fuel gauge reading).
Initially, B and 𝐹 are independent.
If we observe G=0 (fuel gauge shows empty), it creates a dependency between  𝐵and 𝐹.
This means that knowing one cause (e.g., battery is dead) reduces the probability of the other cause (e.g., fuel is empty). This is a key property of Bayesian networks.

8.1.3 Discrete Variables
Introduction
Bayesian networks can be used to model discrete variables, which take values from a finite set (e.g., categories, states, or class labels). These variables are often represented using a 1-of-K encoding (one-hot encoding), where each discrete state is assigned a binary vector.

Probability Distribution for a Single Discrete Variable
A discrete variable 𝑥 with 𝐾 possible states can be described using a multinomial distribution:
p(x∣μ)= ∏ μk^xk 
       k=1     
where:
𝜇=(𝜇1,𝜇2,...,𝜇𝐾) represents the probabilities of the 𝐾 states.
𝑥𝑘 is a binary indicator (1 if 𝑥 is in state 𝑘, otherwise 0).
The probabilities sum to one: ∑ 𝜇𝑘=1
                       k=1 
Since there are 𝐾 probabilities, but they sum to 1, we only need to specify 𝐾−1 independent parameters.

Modeling Two Discrete Variables
For two discrete variables 𝑥1 and 𝑥2 , each with 𝐾 states, the joint probability distribution is given by:
𝑝(𝑥1,𝑥2∣𝜇)=∏ ∏ 𝜇𝑘𝑙^𝑥1𝑘𝑥2𝑙 
         k=1𝑙=1
where 𝜇𝑘𝑙 represents the probability of 𝑥1 being in state 𝑘 and 𝑥2 in state 𝑙.
If 𝑥1 and 𝑥2 are fully dependent, we need to specify K^2−1 parameters.
If 𝑥1 and 𝑥2 are conditionally independent, then the joint probability factorizes: 𝑝(𝑥1,𝑥2)=𝑝(𝑥1)𝑝(𝑥2) and we only need 2(K−1) parameters, reducing the model complexity.

Reducing Complexity in Multi-Variable Distributions
When modeling multiple discrete variables, the number of parameters grows exponentially in a fully connected graph. To manage complexity, we:
Use sparse graphs (drop unnecessary edges) – removing edges reduces the number of dependencies.
Use structured models like chains
Share parameters (parameter tying) – reuse the same probability distribution for different conditional probabilities.

Bayesian Models for Discrete Variables
In Bayesian networks, we can introduce Dirichlet priors over the parameters 𝜇.
- Dirichlet distribution is the conjugate prior for the multinomial distribution.
- A graph with Dirichlet priors has extra parent nodes representing these priors.
For example:
- Without parameter tying: Each conditional distribution 𝑝(𝑥𝑖∣𝑥𝑖−1) has a separate Dirichlet prior.
- With parameter tying: A single shared Dirichlet prior governs all conditional distributions.
This allows Bayesian learning, where we can update our beliefs about 𝜇 as we observe data.

8.1.4 Linear-Gaussian Models
Introduction
A Linear-Gaussian Model is a special case of Bayesian networks where:
- Each node represents a continuous variable.
- The conditional distributions are Gaussian.
- The mean of each node is a linear function of its parents.
Linear-Gaussian models are widely used in:
- Probabilistic PCA
- Factor Analysis
- Kalman Filters and Linear Dynamical Systems

Gaussian Nodes in a Directed Graph
Consider a set of 𝐷 variables x1,x2 ,...,xD in a directed acyclic graph (DAG), where each variable follows a Gaussian distribution:
p(xi∣pai)=N(xi ∑ wijxj +bi,vi)
            j∈pai
where:
pai are the parents of 𝑥𝑖
wij are linear coefficients defining how parents influence 𝑥𝑖.
𝑏𝑖 is a bias term.
𝑣𝑖 is the variance of the Gaussian.
This means each variable is a linear function of its parents plus Gaussian noise.

Factorization of the Joint Gaussian Distribution
The joint distribution of all variables is:
     D
𝑝(𝑥)=∏ 𝑝(𝑥𝑖∣𝑝𝑎𝑖)
    𝑖=1
Since each term is a Gaussian, the entire distribution is a multivariate Gaussian.
Using matrix notation, we can express it as:
x=Wx+b+ϵ
where:
- 𝑊 is a lower-triangular matrix (since it’s a DAG).
- ϵ∼N(0,V) is Gaussian noise.
- The covariance matrix Σ can be computed recursively.

Extreme Cases: Fully Connected vs. Fully Disconnected
Fully Disconnected Graph
- No links between nodes.
- Each variable is an independent Gaussian:
𝑝(𝑥𝑖)=𝑁(𝑏𝑖,𝑣𝑖)
- The covariance matrix is diagonal.

Fully Connected Graph
- Each node depends on all lower-numbered nodes.
- The covariance matrix is full (general Gaussian).

Partially Connected Graph
- Some variables are conditionally independent.
- The covariance matrix has zeros in certain positions.

Hierarchical Bayesian Models
- A Gaussian prior on the mean 𝜇 of another Gaussian variable leads to a joint Gaussian distribution.
- This can be extended to hyperpriors (priors on priors), forming a hierarchical Bayesian model.

Final Thoughts
Discrete Bayesian Networks help with categorical data (e.g., Weather → Mood).
Linear-Gaussian Models help with continuous data (e.g., Study → Score).
Both use graphs to make calculations simpler and more efficient.

8.2 Conditional Independence
it helps simplify probability calculations and reduces the complexity of models.
A variable 𝑎 is conditionally independent of 𝑏, given 𝑐, if: p(a∣b,c)=p(a∣c)
This means that once we know 𝑐, learning about 𝑏 gives us no extra information about 𝑎.
ex. Imagine a student’s grade (G) depends on both their intelligence (I) and the difficulty of the exam (D):
I → G ← D 
Before knowing 𝐺: Intelligence and Difficulty are independent.
After seeing 𝐺: If we learn that the student got an A, and we already know the exam was easy, we might infer they are not very intelligent.
This means I and D become dependent given G, even though they were independent before.

8.2.1 Three Example Graphs
Example 1: Tail-to-Tail Structure 
a->c<-b This means a and 𝑏 both depend on c.
Joint Probability Factorization: (a,b,c)=p(a∣c)p(b∣c)p(c)
Independence Properties:
Without knowing c: a and 𝑏 are mutually exclusive.
Given 𝑐: 𝑎 and 𝑏 become independent
Example in Real Life:
𝑎 = Person's accent, 
b = Person's clothing style, 
𝑐= Their country of origin.
Before knowing their country: Accent and clothing style might seem correlated.
After knowing their country: The correlation disappears—both are simply influenced by the country.

Example 2: Head-to-Tail Structure (Causal Chain)
  a → c → b
This means 𝑎 influences 𝑐, and 𝑐 influences 𝑏.
Factorization: (a,b,c)=p(a)p(c∣a)p(b∣c)
Independence Properties:
Without knowing c: 𝑎 and 𝑏 are dependent.
Given 𝑐: 𝑎 and 𝑏 become independent

Example 3: Head-to-Head Structure (Explaining Away)
  a → c ← b
This means 𝑐 has two possible causes: 𝑎 and 𝑏.
Factorization:
p(a,b,c)=p(a)p(b)p(c∣a,b)
Independence Properties:
Without knowing 𝑐: 𝑎 and 𝑏 are independent.
Given 𝑐: 𝑎 and 𝑏 become dependent → 𝑎 and 𝑏 influence each other.

Example in Real Life (Explaining Away Phenomenon)
Imagine your car won’t start (𝑐). Two possible reasons:
𝑎= The battery is dead.
𝑏 = The fuel tank is empty.
Before checking the car, these two causes are independent. But once you observe that the car won’t start:
If you check and find that the battery is dead, you don’t need to check the fuel—because you already explained the problem.
If the battery is fine, you now strongly suspect the fuel is empty.
This is called "explaining away"—when two independent causes become dependent after observing the effect

8.2.2 D-Separation (Directed Separation) (How to Read Independence from a Graph)
D-Separation Rule:
To check if two sets of nodes 𝐴 and 𝐵 are conditionally independent given 𝐶, follow this rule:

A path is BLOCKED if:
- There is a head-to-tail (→) or tail-to-tail (←) connection, and the middle node is in 𝐶. 
- There is a head-to-head (→ ←) connection, and neither the middle node nor its descendants are in 𝐶.
If ALL paths between 𝐴 and 𝐵 are blocked, then 𝐴 and 𝐵 are conditionally independent given 𝐶.
ex.
a → c → e
        ↓
        d
To check if 𝑎 and 𝑒 are independent given 𝑐:
Path: a→c→e → This is blocked since 𝑐 is given.
Path: a→c→d→e → This is also blocked since 𝑐 is given.
This means if we already know 𝑐, knowing 𝑎 tells us nothing extra about 𝑒.

8.3 Markov Random Fields (Undirected Graphical Models)
Graph type undirected graph
factorization use potential functions 
best for mutual dependencies e.g. pixels in an image 
Why use MRFs?
Some problems don’t have clear directionality (e.g., in an image, neighboring pixels influence each other, but there is no strict "cause-effect" order).
They allow more flexibility in defining relationships between variables

8.3.1 Conditional Independence in MRFs
Just like in Bayesian networks, conditional independence helps simplify MRFs.

How do we check independence?
In Bayesian Networks: We use D-Separation (checking blocked paths).
In MRFs: We use Graph Separation → If removing a set of nodes disconnects two groups, they are conditionally independent.
 A — B — C
 |    |    |
 D — E — F
Are A and C independent?
No, because there is a connection through B.
Are A and C independent given B?
Yes! If we know 𝐵, knowing 𝐴 tells us nothing new about 𝐶.

Markov Blanket in MRFs
In a Markov Network, a node is independent of everything else given its neighbors.
- The Markov Blanket of a node is just its direct neighbors.
- This is simpler than Bayesian networks, where the Markov Blanket includes parents, children, and co-parents.

8.3.2 Factorization Properties of MRFs
Since there are no arrows in MRFs, we can’t use conditional probabilities like in Bayesian networks.
Instead, we use potential functions (also called compatibility functions).
How does an MRF define probabilities?
Instead of expressing the joint probability as a product of conditionals, we write it as: p(x)= 1/Z ∏𝜓c(xc)
where:
𝜓𝐶(𝑥𝐶) is a potential function over a clique C.
Z is the normalization constant to ensure probabilities sum to 1.
ex.  x1 — x2 — x3
The joint probability factorizes as:
p(x1,x2,x3) = 1/Z 𝜓(x1,x2)𝜓(x2,x3)
This says that the probability depends only on neighboring variables, not on all variables at once.
Why is this useful?
It lets us model dependencies flexibly.
Unlike Bayesian Networks, we don’t need to specify a direction—just how variables relate.

8.3.3 Illustration: Image de-noising
Markov Random Fields (MRFs) are used in image de-noising, a common problem in computer vision. The goal is to remove noise from an image while preserving important details, like edges.
How Does Image De-noising Work?
- An image consists of pixels, each having an intensity value (e.g., black & white or color values).
- Due to noise, some pixel values are incorrect (e.g., grainy or blurred areas).
- The key assumption: A pixel’s true value is similar to its neighbors.
MRFs are perfect for this because:
- Each pixel is influenced by its neighbors (mutual dependency, not cause-effect).
- There is no clear directionality, so an undirected graphical model (MRF) is a better fit than a Bayesian Network.

How MRFs Model an Image
1- Graph Representation
- Each pixel is a node in the MRF.
- Each edge connects a pixel to its neighboring pixels.
- This means that each pixel depends only on its neighbors, not the entire image.
2- Probability Model
- The goal is to recover the "true" image (𝑥) from the noisy image (𝑦).
- We define a probability distribution:
𝑝(𝑥)=1/∏𝜓𝐶(𝑥𝐶)
       C
- 𝜓𝐶(𝑥𝐶) represents how smooth the image is (favoring similar neighboring pixel values).
- Z is a normalization factor.
We also model the likelihood of the noisy image 𝑦 given 𝑥:
- p(y∣x)= ∏N(yi∣xi,σ^2)
         i
- This assumes the observed noisy pixel 𝑦𝑖 is close to the true pixel 𝑥𝑖 with Gaussian noise.

How De-noising Works in MRFs
We estimate 𝑥 (true image) by maximizing the posterior probability:
p(x∣y)∝p(y∣x)p(x)
This is done using optimization techniques like:
Iterative algorithms (e.g., Gibbs sampling, Mean Field Approximation).
Belief propagation to estimate the best values for 𝑥.


8.3.4 Relation to directed graphs
Relationship Between Bayesian Networks and MRFs
How are Bayesian Networks and MRFs related?
Any Bayesian Network can be converted into an MRF.
But not every MRF can be represented as a Bayesian Network (because some dependencies can't be expressed with a directed graph).

How do we convert a Bayesian Network to an MRF?
Moralization: In a Bayesian network, some nodes share a common child (e.g., A → C ← B).
In an MRF, we must add a link between these parent nodes (A—B) to make them a clique.
Remove the arrows, keeping only undirected edges.

Example: Convert a Bayesian Network to an MRF
 A → C ← B
Step 1: Remove arrows → Just keep A—B—C as an undirected graph.
The resulting MRF represents the same conditional independence properties, but without directionality.
Bayesian Networks are easier for causal reasoning, while MRFs are better for undirected dependencies
 A — B
   \ /
    C

8.4 Inference in Graphical Models
Inference in graphical models means computing probabilities or expectations of certain variables given observed data.

For example:

Bayesian Networks (Directed Graphs): Given symptoms, infer the probability of a disease.
Markov Random Fields (MRFs) (Undirected Graphs): Given a noisy image, infer the clean image.
Types of Inference
Marginal Inference: Compute 𝑝(𝑥𝑖) for a single variable.
Conditional Inference: Compute 𝑝(𝑥𝑖∣𝑥𝑗), given another variable.
MAP (Maximum a Posteriori) Inference: Find the most likely state 𝑥∗ that maximizes p(x).

8.4.1 Inference on a Chain
Graphical Models as Chains
One of the simplest structures in graphical models is a chain, where variables depend on each other sequentially:
x1 → x2 → x3 → x4
Each node depends only on its neighbor(s). This appears in:
Hidden Markov Models (HMMs) (sequence data).
Markov Chains (probability transitions).

We want to find:Marginal Probability
p(xk)= ∑p(x1,x2,...,xN)
      𝑥−𝑘
where 𝑥−𝑘  means sum over all variables except 𝑥𝑘.

Forward-Backward Algorithm
Forward Pass: Compute messages from left to right.
Backward Pass: Compute messages from right to left.

Figure 8.38 The marginal distribution
p(xn) for a node xn along the chain is obtained
by multiplying the two messages
μα(xn) and μβ(xn), and then normalizing.
These messages can themselves
be evaluated recursively by passing messages
from both ends of the chain towards
node xn.

8.4.2 Trees
What are Trees?
A tree is a graph where there is only one path between any two nodes.

Example: A hierarchical model
        A
       / \
      B   C
     / \   \
    D   E   F

Why Are Trees Important?
Fast inference: We can compute probabilities efficiently.
Many real-world models are trees (e.g., decision trees, phylogenetic trees in biology).
Inference on Trees: Belief Propagation
Similar to forward-backward on a chain, but works on trees.
Each node sends messages to its neighbors summarizing probability information.

8.4.3 Factor Graphs
Why Factor Graphs?
Sometimes, directly representing a probability distribution is too complex.
Instead, we break it into factors.

Example: Bayesian Network
 A → B → C
(a,b,c)=p(a)p(b|a)p(a|b)
A factor graph explicitly shows how variables depend on factors:
Circles (nodes) → Variables.
Squares (factors) → Conditional probabilities.

8.4.4 The Sum-Product Algorithm
What is the Sum-Product Algorithm?
A message-passing algorithm used in factor graphs for efficient inference.

How It Works
Each node sends messages to its neighbors:

Summing out non-relevant variables (to simplify computation).
Multiplying messages to compute probabilities.
Why is this Useful?
It’s much faster than brute-force marginalization.
Used in error correction codes, speech recognition, and AI

8.4.5 The Max-Sum Algorithm
What is the Max-Sum Algorithm?
The Max-Sum Algorithm (also called the Viterbi algorithm in some contexts) is used for Maximum a Posteriori (MAP) inference.

In the Sum-Product Algorithm, we computed marginal probabilities (summing over variables).
In the Max-Sum Algorithm, instead of summing, we maximize the probability to find the most likely configuration (MAP estimate).
Where is it Used?
Hidden Markov Models (HMMs) → Finding the most likely sequence of hidden states.
Computer Vision → Finding the best segmentation of an image.
Error Correction → Finding the most probable transmitted message.
How It Works
The Sum-Product Algorithm computes: p(x)=∑ψ(x,y)
                                         y

The Max-Sum Algorithm replaces the sum with max
This finds the best possible assignment for the variables.
It still uses message passing like the Sum-Product Algorithm.


8.4.6 Exact Inference in General Graphs
Why is Exact Inference Hard?
In chains and trees, inference is fast using message passing.
But in general graphs (with cycles), inference is NP-hard (exponentially slow).
To handle general graphs, we use the Junction Tree Algorithm:
Convert the graph into a tree (a junction tree).
Run belief propagation on this tree.
Steps:
Triangulation: Add extra edges to remove cycles.
Form Cliques: Group variables into cliques.
Run Message Passing on the junction tree.
Cliques : a subset of vertices of an undirected graph such that every two distinct vertices in the clique are adjacent

8.4.7 Loopy Belief Propagation
What is Loopy Belief Propagation (LBP)?
When a graph has cycles, exact inference isn’t feasible.
Instead, we use an approximate method called Loopy Belief Propagation (LBP).
How It Works:
Ignore cycles and still run message passing like in a tree.
Iterate multiple times until probabilities converge.
Works well in many cases, even though it's not exact.
Used in error correction codes (Turbo codes), image denoising, and deep learning.
If the graph has strong cycles, messages might oscillate instead of converging.

8.4.8 Learning the Graph Structure
Why Learn the Graph Structure?
In real-world problems, we don’t always know how variables are connected.
We must learn the structure from data.
Two Approaches to Learning:
Constraint-Based Learning

Uses statistical tests to find conditional independence.
Example: If 𝐴 and 𝐶 are independent given 𝐵, we remove the edge A−C.
Score-Based Learning
Assigns a score to different graph structures and finds the best one.
Example: Bayesian Information Criterion (BIC) and Bayesian Score measure how well the graph fits the data.

✔ Chains and trees allow efficient probability calculations using message passing.
✔ Factor graphs break complex models into simple factors.
✔ The sum-product algorithm speeds up inference significantly.
✔ Max-Sum Algorithm → Finds the most probable state instead of marginal probabilities.
✔ Junction Tree Algorithm → Converts complex graphs into trees for exact inference.
✔ Loopy Belief Propagation → Approximate inference in graphs with cycles.
✔ Learning Graph Structures → Discovering relationships directly from data.




































































































































