3.1. Linear Basis Function Models
- Linear basis function models are extensions of simple linear regression.
- a linear function of the input variables xi, and this imposes significant limitations on the model. We therefore extend the class of models by considering
linear combinations of fixed nonlinear functions of the input variables
- Instead of working directly with the input variables (ğ‘¥1,x2,â€¦), these models transform inputs using functions called basis functions (ğœ™ğ‘—(ğ‘¥)).
This form remains linear in the parameters , even if basis is nonlinear and the model can capture complex relationships in the data.

Examples of Basis Functions:
Gaussian:  where Î¼jâ€‹ controls the center and s controls the spread.
Sigmoidal , ploynomial 

3.1.1 Maximum likelihood and least squares
- it expect that the noise data t is gaussion?
- Maximizing the log-likelihood with respect to w is equivalent to minimizing the sum-of-squares error function ED(w).
- The precision parameter ğ›½ (or its inverse, the noise variance) can also be estimated, which is the residual variance of the target values around the model's predictions.

 3.1.2: Geometry of Least Squares
The least-squares solution has a natural interpretation in an N-dimensional space, represents the target values as a vector.
The error minimization process (least-squares) corresponds to finding the projection of ğ‘¡ onto ğ‘† ensuring that ğ‘¦ is the closest point to ğ‘¡ in this subspace.
The least-squares solution achieves this by making the residual (difference between ğ‘¡ and ğ‘¦) orthogonal to ğ‘†
The residuals are the vertical distances from the points to the line. The least-squares solution ensures that these residuals are perpendicular to the line, which geometrically corresponds to finding the closest line to all points.

3.1.3: Sequential Learning
- Batch Learning: Involves processing the entire dataset at once, which can be computationally expensive for large datasets.
- Sequential Learning: Processes data one point at a time, updating the model incrementally.
- Stochastic Gradient Descent (SGD)
The sequential learning method is based on stochastic gradient descent (SGD), which minimizes the error function by updating the parameter vector ğ‘¤ iteratively for subset of data:

3.1.4: Regularized Least Squares
adding a regularization term to an error function in order to control over-fitting
- known in the machine learning literature as weight decay because in sequential learning algorithms, it encourages weight values to decay towards zero, unless supported by the data.
- Alternative Regularization Terms: More general forms, such as 
M
âˆ‘
ğ‘—=1 âˆ£ğ‘¤ğ‘—âˆ£ğ‘,
can be used for regularization.
For q=1, the method is called lasso, which promotes sparsity by driving some weights to zero.


3.1.5: Multiple Outputs
In some applications, instead of predicting a single target variable ğ‘¡, you might need to predict multiple outputs simultaneously. These target variables are represented as a vector ğ‘¡ with ğ¾>1 components.
- y(x,w)=WTÏ•(x),where:
ğ‘¦(ğ‘¥,ğ‘¤) is a ğ¾-dimensional output vector. 
ğ‘Š is an ğ‘€Ã—ğ¾ parameter matrix. 
ğœ™(ğ‘¥) is an ğ‘€-dimensional vector of basis functions.

 3.2: The Bias-Variance Decomposition
Expected Squared Loss: The goal is to minimize the expected squared loss between predictions ğ‘¦(ğ‘¥) and the true regression function â„(ğ‘¥)  first term measures the accuracy of predictions, while the second term represents the intrinsic noise in the data.
- The squared loss is broken into three components: ExpectedÂ Loss=(Bias)2+Variance+Noise.
Bias: Measures how far the average prediction is from the true function â„(ğ‘¥).
Variance: Reflects the sensitivity of the model to different training data sets.
Noise: Represents the irreducible error due to randomness in the data.
- There is a trade-off between bias and variance:
Flexible models (e.g., high-degree polynomials) have low bias but high variance.
Rigid models (e.g., simple linear functions) have high bias but low variance.
The optimal model balances bias and variance to minimize total error.

3.3. Bayesian Linear Regression
- Adding a regularization term to the log likelihood function means the effective model complexity can then be controlled by the value of the regularization coefficient,

- We turn to a Bayesian treatment of linear regression, which will avoid the over-fitting problem of maximum likelihood, and which will also lead to automatic methods of determining model complexity using the training data alone.


3.3.1 Parameter distribution
-  Bayesian methods, which provide a principled way to incorporate prior knowledge and handle uncertainty in parameter estimates
noise precision parameter Î² as a known constant.
- In Bayesian linear regression, the parameters ğ‘¤ of the model are treated as random variables.
- A prior distribution is assigned to ğ‘¤, reflecting our initial belief about its values before observing any data.
- A Gaussian prior is commonly used: ğ‘(ğ‘¤)=ğ‘(ğ‘¤âˆ£ğ‘š0,ğ‘†0),
where ğ‘š0 is the prior mean and ğ‘†0 is the prior covariance matrix.
-  prior is updated to a posterior distribution using Bayes' theorem: p(wâˆ£t)âˆp(tâˆ£w)p(w),
where  p(tâˆ£w) is the likelihood of the data given w.
The posterior distribution is also Gaussian due to the conjugate properties of Gaussian priors and likelihoods
- The posterior mean ğ‘šğ‘ and covariance ğ‘†ğ‘ are computed as where Î¦ is the design matrix, ğ‘¡ is the vector of observed targets, and ğ›½ is the noise precision.
Special Cases:
- If the prior is broad (S0âˆ’1â†’0), the posterior mean reduces to the maximum likelihood solution.
- When no data is available (N=0), the posterior reverts to the prior.
- Sequential Updates: Bayesian learning allows for sequential updates: the posterior after observing one dataset serves as the prior for the next dataset.

3.3.2: Predictive Distribution
- The main goal is to predict the target value ğ‘¡ for a new input ğ‘¥, using the Bayesian framework. This involves marginalizing over the posterior distribution of the model parameters.
- he predictive distribution is given by: 
	integrating Likelihood of the target variable given the model parameters. with Posterior distribution of the parameters.
	Because both the likelihood and posterior are Gaussian, the predictive distribution is also Gaussian:
	As more data points are observed, the posterior becomes more confident (narrower), and the second term in the variance diminishes.
	In the limit of infinite data, the uncertainty arises solely from the noise.
	the model's predictive uncertainty is higher in regions with fewer data points and reduces as more data is observed. 

3.3.3: Equivalent Kernel?
The equivalent kernel provides an interpretation of Bayesian linear regression in terms of kernel methods.
It describes how predictions are formed as a weighted combination of the training data's target values.

3.4: Bayesian Model Comparison
Bayesian model comparison, which evaluates models using probabilities, providing a principled way to select among competing models based on observed data. Key points are:
Posterior Model Probability
1- The posterior probability of a model ğ‘€ğ‘– given data ğ· is:
	p(Mi): Prior probability, representing initial preference for the model. 
	ğ‘(ğ·âˆ£ğ‘€ğ‘–): Model evidence or marginal likelihood, measures how well the model explains the data.

2- Model Evidence
The model evidence ğ‘(ğ·âˆ£ğ‘€ğ‘–) is computed by marginalizing over the model parameters ğ‘¤:
This integral balances:
	Fit to the data: How well the model matches the observations.
	Complexity penalty: Penalizes overly complex models to avoid overfitting.

3. Bayes Factor
The ratio of evidences for two models is called the Bayes factor It quantifies the relative evidence for two models based on the observed data.

4. Model Averaging
Rather than selecting a single model, predictions can be made by averaging over all models, weighted by their posterior probabilities

5- Model Complexity Trade-off
Simple models may underfit, providing poor data fit.
Complex models may overfit, spreading probability across many data sets and penalizing evidence.
The optimal model balances complexity and fit.

6-  General Insights
Bayesian model comparison avoids overfitting by incorporating a complexity penalty.
Predictions and model evaluations are based on the training data, eliminating the need for a separate validation set.
The method is sensitive to prior choices and assumptions.



3.6: Limitations of Fixed Basis Functions
1. Dependency on Basis Functions Linear models rely on a fixed set of basis functions which transform the input ğ‘¥ into a new representation: Key limitations arise due to the choice and properties of these basis functions.

2. Limitations

Model Complexity:
The complexity of the model is determined by the number of basis functions ğ‘€ A small ğ‘€ may lead to underfitting, while a large ğ‘€ may result in overfitting or numerical instability.

Choice of Basis Functions:
The performance of the model depends critically on the type of basis functions used (e.g., polynomials, Gaussians, sigmoids).
Poorly chosen basis functions may fail to capture important data features.

Fixed Nature:
Fixed basis functions do not adapt to the data, which can limit their flexibility and effectiveness, especially for complex datasets.

Scalability:
In high-dimensional input spaces, the number of basis functions required grows rapidly, leading to computational challenges (the curse of dimensionality).

Extrapolation Issues:
Fixed basis functions, such as localized Gaussians, may generalize poorly outside the region covered by the data, resulting in overconfidence in predictions in unobserved regions.

Feature Engineering Dependency:
Fixed basis function models often require extensive pre-processing or feature engineering to construct effective basis functions tailored to the problem.

3.1.3: Sequential Learning
Sequential learning, based on stochastic gradient descent, updates model parameters incrementally with each data point, making it efficient for large datasets and real-time applications. While it offers adaptability and reduced computational demands, careful tuning of the learning rate is essential for stability and convergence.





















